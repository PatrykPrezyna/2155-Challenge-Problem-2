{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65478191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_public import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "grids = load_grids()\n",
    "ratings = np.load(\"datasets/scores.npy\")\n",
    "ratings_df = pd.DataFrame(ratings, columns=[\"Wellness\", \"Tax\", \"Transportation\", \"Business\"])\n",
    "\n",
    "advisor = 1 #select advisor 0 for now. \n",
    "grids_subset, ratings_subset = select_rated_subset(grids, ratings[:,advisor]) #gets subset of the dataset \n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(grids_subset, ratings_subset, test_size=.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ef66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58131c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, Y_train, X_validation, Y_validation, num_epochs=10, batch_size=32, learning_rate=0.001, device='cuda'):\n",
    "    \"\"\"\n",
    "    Function to train a given model (CNN or DNN) using training and validation data.\n",
    "\n",
    "    Args:\n",
    "    - model: The model to train (e.g., CNN or DNN).\n",
    "    - X_train: Training data (features).\n",
    "    - Y_train: Training data (labels).\n",
    "    - X_validation: Validation data (features).\n",
    "    - Y_validation: Validation data (labels).\n",
    "    - num_epochs: Number of training epochs (default: 10).\n",
    "    - batch_size: Batch size for training (default: 32).\n",
    "    - learning_rate: Learning rate for the optimizer (default: 0.001).\n",
    "    - device: Device to run the model on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    - train_losses: List of training losses for each epoch.\n",
    "    - val_losses: List of validation losses for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Move model to the specified device (GPU or CPU)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define loss function (Mean Squared Error for regression tasks)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Define optimizer (Adam optimizer with specified learning rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create DataLoader for batching the training data\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(Y_train, dtype=torch.float32))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Create DataLoader for batching the validation data\n",
    "    validation_dataset = TensorDataset(torch.tensor(X_validation, dtype=torch.float32), torch.tensor(Y_validation, dtype=torch.float32))\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Lists to store train and validation losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Using tqdm for the training loop progress bar\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f'Epoch [{epoch + 1}/{num_epochs}]', leave=False)\n",
    "\n",
    "        # Iterate over batches of training data\n",
    "        for inputs, labels in train_loader_tqdm:\n",
    "            inputs = inputs.to(device)  # Move inputs to device (GPU/CPU)\n",
    "            labels = labels.to(device)  # Move labels to device (GPU/CPU)\n",
    "\n",
    "            # Zero the gradients before the next update\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: compute model outputs\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass: compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform a single optimization step (update model parameters)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss over the batch\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Update tqdm progress bar with current loss\n",
    "            train_loader_tqdm.set_postfix({'Train Loss': running_loss / len(train_loader.dataset)})\n",
    "\n",
    "        # Calculate average training loss for the epoch\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        # Validation loop (no gradient computation)\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in validation_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass: compute model outputs\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute validation loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Calculate average validation loss for the epoch\n",
    "        val_loss /= len(validation_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Print the train and validation loss at the end of each epoch\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] - Train MSE: {epoch_loss:.4f} - Validation MSE: {val_loss:.4f}')\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # Return the recorded training and validation losses\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c62308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):  # Define all the layers here\n",
    "        super(CNN, self).__init__()\n",
    "        # All pooling will use 2x2 window and stride 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # First Conv layer: 1 input channel (grayscale), 4 output channels, kernel size 3x3, stride 1, padding 1\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Second Conv layer: 4 input channels, 8 output channels\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Third Conv layer: 8 input channels, 16 output channels\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Fourth Conv layer: 16 input channels, 32 output channels\n",
    "        self.conv4 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Operation to flatten the images into a vector\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 3 * 3, 16)  # Adjusted to match the output size after conv3\n",
    "        self.fc2 = nn.Linear(16, 5)  # 5 output classes\n",
    "\n",
    "    def forward(self, x):  # Call all the layers in this function\n",
    "        # Reshape the input to ensure it has the correct channel dimension: [batch x 1 x 50 x 50]\n",
    "        if len(x.shape) == 3:  # Input is [batch x 50 x 50]\n",
    "            x = x.unsqueeze(1)  # Add channel dimension -> [batch x 1 x 50 x 50]\n",
    "\n",
    "        # Convolve, then pass through ReLU, then pooling\n",
    "        x = F.relu(self.conv1(x))  # [batch x 4 x 50 x 50]\n",
    "        x = self.pool(x)  # [batch x 4 x 25 x 25]\n",
    "\n",
    "        x = F.relu(self.conv2(x))  # [batch x 8 x 25 x 25]\n",
    "        x = self.pool(x)  # [batch x 8 x 12 x 12]\n",
    "\n",
    "        x = F.relu(self.conv3(x))  # [batch x 16 x 12 x 12]\n",
    "        x = self.pool(x)  # [batch x 16 x 6 x 6]\n",
    "\n",
    "        x = F.relu(self.conv4(x))  # [batch x 32 x 6 x 6]\n",
    "        x = self.pool(x)  # [batch x 32 x 3 x 3]\n",
    "\n",
    "        x = self.flatten(x)  # Flatten for the fully connected layer [batch x 288]\n",
    "\n",
    "        # Pass through fully connected layers with ReLU\n",
    "        x = F.relu(self.fc1(x))  # [batch x 16]\n",
    "\n",
    "        # Final fully connected layer with no activation (since we are doing regression)\n",
    "        x = self.fc2(x)  # Output layer with 5 outputs [batch x 5]\n",
    "        return x\n",
    "\n",
    "# Create a CNN model instance\n",
    "model_cnn = CNN()\n",
    "model_cnn.to(device)\n",
    "\n",
    "# Print the model's architecture\n",
    "summary(model_cnn, input_size=(1, 50, 50))  # Adjusted input size for grayscale images with 1 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ce001",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_train_losses, cnn_val_losses = train_model(model_cnn, X_train, Y_train, X_validation, Y_validation, num_epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf36a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
