{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65478191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from utils_public import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "def plot_and_r2(preds_train, preds_test, ratings_train, ratings_test, advisor): \n",
    "    #Calculates \n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.scatter(ratings_train, preds_train, label='Train Set Preds', s=3, c = \"#BBBBBB\") #train set in gray\n",
    "    plt.scatter(ratings_test, preds_test, label='Test Set Preds', s=5, c = \"#DC267F\") #test set in magenta\n",
    "    plt.plot([0,1], [0,1], label=\"Target\", linewidth=3, c=\"k\") #target line in black\n",
    "\n",
    "    #Set axis labels and title\n",
    "    plt.xlabel(\"Actual Rating\")\n",
    "    plt.ylabel(\"Predicted Rating\")\n",
    "    plt.title(f\"Advisor {advisor} Predictions\")\n",
    "\n",
    "    #Turn off top and right spines\n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    plt.legend() #Display legend\n",
    "    plt.show() #Show plot\n",
    "\n",
    "    #Calculate R2 score for train and test sets\n",
    "    print(f\"Advisor {advisor} Train Set R2 score: {r2_score(ratings_train, preds_train)}\") \n",
    "    print(f\"Advisor {advisor} Test Set R2 score: {r2_score(ratings_test, preds_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf78372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and run the model\n",
    "grids = load_grids()\n",
    "ratings = np.load(\"datasets/scores.npy\")\n",
    "ratings_df = pd.DataFrame(ratings, columns=[\"Wellness\", \"Tax\", \"Transportation\", \"Business\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aecb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "num_iterations = 20  # how many new grids to create per original grid\n",
    "num_cell_to_replace = 1  # how many cells to modify in each new grid\n",
    "\n",
    "new_grids = []\n",
    "new_ratings = []\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    for grid in grids:\n",
    "        # Generate modified versions of the grid\n",
    "        new_grid = grid.copy()\n",
    "        for _ in range(num_cell_to_replace):\n",
    "            # Select random cell coordinates\n",
    "            x, y = random.randint(0, 6), random.randint(0, 6)\n",
    "            current_val = grid[x, y]\n",
    "            # Choose a different random value for replacement\n",
    "            new_val = random.choice([v for v in range(5) if v != current_val])\n",
    "            new_grid[x, y] = new_val\n",
    "        new_grids.append(new_grid)\n",
    "        new_ratings.append([np.nan] * 4)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "new_grids = np.array(new_grids)\n",
    "new_ratings = np.array(new_ratings)\n",
    "\n",
    "# Combine with existing data\n",
    "all_grids = np.vstack((grids, new_grids))\n",
    "all_ratings = np.vstack((ratings, new_ratings))\n",
    "\n",
    "# Remove duplicates\n",
    "unique_grids, unique_indices = np.unique(all_grids, axis=0, return_index=True)\n",
    "unique_ratings = all_ratings[unique_indices]\n",
    "\n",
    "print(f\"Number of unique grids: {unique_grids.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture for 7x7 grid prediction\n",
    "def create_grid_cnn(input_shape=(7, 7, 5)):\n",
    "    \"\"\"\n",
    "    Create a CNN model optimized for 7x7 grid prediction.\n",
    "\n",
    "    Architecture features:\n",
    "    - Small kernels (2x2, 3x3) to capture local patterns\n",
    "    - Residual connections to help with gradient flow\n",
    "    - Batch normalization for stable training\n",
    "    - Dropout for regularization\n",
    "    - Appropriate padding to maintain spatial information\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # First convolutional block\n",
    "    x = layers.Conv2D(32, kernel_size=3, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x1 = x  # Store for residual connection (will project to match channels when needed)\n",
    "\n",
    "    # Second convolutional block\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Third convolutional block with residual connection\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Project the earlier x1 (32 channels) to match 64 channels before adding\n",
    "    x1_proj = layers.Conv2D(64, kernel_size=1, padding='same')(x1)\n",
    "    x1_proj = layers.BatchNormalization()(x1_proj)\n",
    "\n",
    "    x = layers.Add()([x, x1_proj])  # Residual connection (now channel shapes match)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    # Fourth convolutional block\n",
    "    x = layers.Conv2D(128, kernel_size=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Global pooling instead of flattening\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Dense layers\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(128, activation='sigmoid')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "all_predictions = [] #empty list to hold predictions\n",
    "histories = []  # Store training histories for each advisor\n",
    "for advisor in range(4): #loop over four advisors\n",
    "    print(f\"\\nTraining model for Advisor {advisor}\")\n",
    "    grids_subset, ratings_subset = select_rated_subset(grids, ratings[:,advisor]) #gets subset of the dataset \n",
    "    X_train, X_validation, Y_train, Y_validation = train_test_split(grids_subset, ratings_subset, test_size=.2, random_state=42)\n",
    "\n",
    "    height, width = 7, 7\n",
    "    num_pixel_classes = 5  # pixels take values 0 to 4\n",
    "    # # One-hot encoding of categorical pixel values\n",
    "    X_train_encoded = tf.one_hot(X_train, depth=num_pixel_classes)  # Shape: (4000, 7, 7, 5)\n",
    "    X_validation_encoded = tf.one_hot(X_validation, depth=num_pixel_classes)  # Shape: (4000, 7, 7, 5)\n",
    "\n",
    "    # Create and compile model\n",
    "    model = create_grid_cnn(input_shape=(height, width, num_pixel_classes))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    # Print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Train the model and capture history\n",
    "    history = model.fit(\n",
    "        X_train_encoded, \n",
    "        Y_train, \n",
    "        batch_size=32, \n",
    "        epochs=100,  # Increased epochs since we have early stopping\n",
    "        validation_data=(X_validation_encoded, Y_validation),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    histories.append(history)\n",
    "\n",
    "    # #predict\n",
    "    preds_train = model.predict(X_train_encoded) #predict on the train set\n",
    "    preds_test = model.predict(X_validation_encoded) #predict on the test set\n",
    "\n",
    "    plot_and_r2(preds_train, preds_test, Y_train, Y_validation, advisor)\n",
    "\n",
    "    grids_encoded = tf.one_hot(unique_grids, depth=num_pixel_classes)  # Shape: (X, 7, 7, 5)\n",
    "    # Merge predictions with actual ratings\n",
    "    predictions = model.predict(grids_encoded) #predict on the train set\n",
    "\n",
    "    mask = np.where(~np.isnan(ratings[:,advisor])) #get the indices of the rated grids\n",
    "    predictions[mask, 0] = ratings[:, advisor][mask]  # assign to 2D predictions\n",
    "    all_predictions.append(predictions) #append predictions\n",
    "    all_predictions = [np.squeeze(a) for a in all_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence curves for all advisors\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot MSE Loss\n",
    "plt.subplot(2, 1, 1)\n",
    "for idx, history in enumerate(histories):\n",
    "    plt.plot(history.history['loss'], label=f'Advisor {idx} Training Loss (MSE)')\n",
    "    plt.plot(history.history['val_loss'], label=f'Advisor {idx} Validation Loss (MSE)', linestyle='--')\n",
    "plt.title('Model Loss (MSE) over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot MAE\n",
    "plt.subplot(2, 1, 2)\n",
    "for idx, history in enumerate(histories):\n",
    "    plt.plot(history.history['mae'], label=f'Advisor {idx} Training MAE')\n",
    "    plt.plot(history.history['val_mae'], label=f'Advisor {idx} Validation MAE', linestyle='--')\n",
    "plt.title('Model MAE over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics for each advisor\n",
    "for idx, history in enumerate(histories):\n",
    "    print(f\"\\nAdvisor {idx} final metrics:\")\n",
    "    print(f\"Training Loss (MSE): {history.history['loss'][-1]:.4f}\")\n",
    "    print(f\"Validation Loss (MSE): {history.history['val_loss'][-1]:.4f}\")\n",
    "    print(f\"Training MAE: {history.history['mae'][-1]:.4f}\")\n",
    "    print(f\"Validation MAE: {history.history['val_mae'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b9ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = np.where(~np.isnan(ratings[:,advisor])) #get the indices of the rated grids\n",
    "# # predictions = predictions.reshape(-1, predictions.shape[0])\n",
    "# predictions[mask, 0] = ratings[:, advisor][mask]  # assign to 2D predictions\n",
    "# # predictions[mask] = ratings[:,advisor][mask] #replace the predictions with the actual ratings where available\n",
    "# all_predictions.append(predictions) #append predictions\n",
    "\n",
    "\n",
    "final_prediction_array = np.stack(all_predictions).T #stack the predictions\n",
    "min_predictions = np.min(final_prediction_array, axis=1) #minimum advisor score (as predicted)\n",
    "# print(f\"Number of valid grids (as predicted): {np.sum((min_predictions > 0.9) & (min_predictions < 1.1))}\") #number of valid grids (as predicted)\n",
    "print(f\"Number of valid grids (as predicted): {np.sum(min_predictions > 0.8)}\") #number of valid grids (as predicted)\n",
    "top_100_indices = np.argpartition(min_predictions, -100)[-100:] #indices of top 100 designs (as sorted by minimum advisor score)\n",
    "\n",
    "\n",
    "top_100_grids = unique_grids[top_100_indices] #get the top 100 grids\n",
    "print(f\"top_100_grids: {top_100_grids[:1]}\")\n",
    "\n",
    "#take the second best 100 from top 200\n",
    "top_500_indices = np.argpartition(min_predictions, -5000)[-5000:]  # indices of top 200 designs\n",
    "top_500_indices = top_500_indices[np.argsort(-min_predictions[top_500_indices])] #sort\n",
    "final_prediction_array[top_500_indices[:100]]\n",
    "# top_100_grids = unique_grids[top_500_indices[100:200]] #get the top 100 grids\n",
    "top_500_grids = unique_grids[top_500_indices] #get the top 500 grids\n",
    "\n",
    "min_predictions_top5 = np.min(top_100_grids, axis=1) #minimum advisor score (as predicted)\n",
    "# print(top_100_grids.shape)\n",
    "# print(f\"top_100_grids: {top_100_grids[:1]}\")\n",
    "# final_prediction_array[top_100_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2624332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_grids\n",
    "final_prediction_array = np.stack(all_predictions).T #stack the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f06c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb7e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grid_distance(grid1, grid2):\n",
    "    \"\"\"Compute the distance between two grids based on element-wise differences\"\"\"\n",
    "    return np.sum(grid1 != grid2)  # Count different elements\n",
    "\n",
    "def select_diverse_grids(grids, n_select=100):\n",
    "    \"\"\"\n",
    "    Select n_select most diverse grids from the input grids using a greedy approach.\n",
    "    Args:\n",
    "        grids: numpy array of shape (N, 7, 7) containing grid designs\n",
    "        n_select: number of grids to select\n",
    "    Returns:\n",
    "        numpy array of shape (n_select, 7, 7) containing selected diverse grids\n",
    "    \"\"\"\n",
    "    n_grids = len(grids)\n",
    "    \n",
    "    # Start with the first grid\n",
    "    selected_indices = [0]\n",
    "    remaining_indices = list(range(1, n_grids))\n",
    "    \n",
    "    # Greedy selection: at each step, select the grid that is most different from already selected ones\n",
    "    for _ in range(n_select - 1):\n",
    "        max_min_distance = -1\n",
    "        best_idx = -1\n",
    "        \n",
    "        # For each remaining grid\n",
    "        for idx in remaining_indices:\n",
    "            # Compute minimum distance to any selected grid\n",
    "            min_distance = float('inf')\n",
    "            for selected_idx in selected_indices:\n",
    "                distance = compute_grid_distance(grids[idx], grids[selected_idx])\n",
    "                min_distance = min(min_distance, distance)\n",
    "            \n",
    "            # Update best candidate if this grid has a larger minimum distance\n",
    "            if min_distance > max_min_distance:\n",
    "                max_min_distance = min_distance\n",
    "                best_idx = idx\n",
    "        \n",
    "        # Add the best grid to selected and remove from remaining\n",
    "        selected_indices.append(best_idx)\n",
    "        remaining_indices.remove(best_idx)\n",
    "    \n",
    "    return grids[selected_indices]\n",
    "\n",
    "# Select 100 most diverse grids from top 500\n",
    "diverse_grids = select_diverse_grids(top_500_grids, n_select=100)\n",
    "print(f\"Selected {len(diverse_grids)} diverse grids\")\n",
    "\n",
    "# Calculate average pairwise distance to verify diversity\n",
    "total_distance = 0\n",
    "n_pairs = 0\n",
    "for i in range(len(diverse_grids)):\n",
    "    for j in range(i + 1, len(diverse_grids)):\n",
    "        total_distance += compute_grid_distance(diverse_grids[i], diverse_grids[j])\n",
    "        n_pairs += 1\n",
    "\n",
    "avg_distance = total_distance / n_pairs\n",
    "print(f\"Average pairwise distance between selected grids: {avg_distance:.2f} different elements\")\n",
    "\n",
    "# Show shape of the selected grids\n",
    "print(f\"Shape of selected grids: {diverse_grids.shape}\")\n",
    "\n",
    "# Update top_100_grids with the diverse selection\n",
    "top_100_grids = diverse_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e8bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ratings_histogram(final_prediction_array, withmin=False) #plot histograms of top 100 designs\n",
    "score = diversity_score(top_100_grids)\n",
    "print(f\"Hypothetical diversity score if all top 100 grids are valid: {score:.4f} \")\n",
    "\n",
    "final_submission = top_100_grids.astype(int)\n",
    "assert final_submission.shape == (100, 7, 7)\n",
    "assert final_submission.dtype == int\n",
    "assert np.all(np.greater_equal(final_submission, 0) & np.less_equal(final_submission, 4))\n",
    "id = np.random.randint(1e8, 1e9-1)\n",
    "np.save(f\"results/{id}.npy\", final_submission)\n",
    "print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba806a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = diversity_score(top_100_grids)\n",
    "print(f\"Hypothetical diversity score if all top 100 grids are valid: {score:.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a371f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_submission = top_100_grids.astype(int)\n",
    "assert final_submission.shape == (100, 7, 7)\n",
    "assert final_submission.dtype == int\n",
    "assert np.all(np.greater_equal(final_submission, 0) & np.less_equal(final_submission, 4))\n",
    "id = np.random.randint(1e8, 1e9-1)\n",
    "np.save(f\"results/{id}.npy\", final_submission)\n",
    "print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission Successful!\n",
    "Name: P&A\n",
    "Nickname: P&A\n",
    "# Invalid grids: 5\n",
    "Mean advisor rating (all advisors, all grids): 0.9523465547605141\n",
    "Score: 0.4956\n",
    "Submission ID: bc9481fc-aaa9-4a46-87df-798fa1f1c9d2\n",
    "\n",
    "Submission Successful!\n",
    "Name: P&A\n",
    "Nickname: P&A\n",
    "# Invalid grids: 0\n",
    "Mean advisor rating (all advisors, all grids): 0.9685816680563087\n",
    "Score: 0.5281142857142858\n",
    "Submission ID: 121d0fd3-1b9b-4a9b-97ac-5a6fbeb02cbf\n",
    "\n",
    "Submission Successful!\n",
    "Name: P&A\n",
    "Nickname: P&A\n",
    "# Invalid grids: 0\n",
    "Mean advisor rating (all advisors, all grids): 0.9711090626078004\n",
    "Score: 0.5065795918367347\n",
    "Submission ID: 13b28d1a-3d76-4bd4-91a7-95cb1516d445\n",
    "\n",
    "Submission Successful!\n",
    "Name: P&A\n",
    "Nickname: P&A\n",
    "# Invalid grids: 0\n",
    "Mean advisor rating (all advisors, all grids): 0.9741715630958115\n",
    "Score: 0.45702448979591836\n",
    "Submission ID: e62da564-c68e-4f47-86cc-703cfa001fff\n",
    "\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 1\n",
    "Mean advisor rating (all advisors, all grids): 0.9572605151740811\n",
    "Score: 0.5132081632653062\n",
    "Submission ID: 84fe22d8-d223-4af5-95c8-a07e52e95d28\n",
    "\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 0\n",
    "Mean advisor rating (all advisors, all grids): 0.9725441426266319\n",
    "Score: 0.48675510204081635\n",
    "Submission ID: 706baab0-4ced-4005-a7d4-0dd37bc1f5c6\n",
    "\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 12\n",
    "Mean advisor rating (all advisors, all grids): 0.9528679005486089\n",
    "Score: 0.41\n",
    "Submission ID: 66cc4520-cb89-4a13-b051-494a7cd10873\n",
    "\n",
    "\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 5\n",
    "Mean advisor rating (all advisors, all grids): 0.9638089872443311\n",
    "Score: 0.4572857142857143\n",
    "Submission ID: 22f26771-1ff7-4067-ad75-84a3688d4a63\n",
    "\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 4\n",
    "Mean advisor rating (all advisors, all grids): 0.9656329994097232\n",
    "Score: 0.4459673469387755\n",
    "Submission ID: ea60ec34-a00c-407b-a6ee-3ab9bb793c46\n",
    "\n",
    "\n",
    "---\n",
    "top 100\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 5\n",
    "Mean advisor rating (all advisors, all grids): 0.9596925926849548\n",
    "Score: 0.40858367346938773\n",
    "Submission ID: 61199621-5c5c-4f38-9122-f87615f8cc8e\n",
    "\n",
    "top second 100\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 11\n",
    "Mean advisor rating (all advisors, all grids): 0.9523805852710479\n",
    "Score: 0.3774\n",
    "Submission ID: 2254a970-e1ca-4bd5-9656-f13a36f728c5\n",
    "\n",
    "\n",
    "top third 100\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 9\n",
    "Mean advisor rating (all advisors, all grids): 0.9462318970556141\n",
    "Score: 0.4081102040816327\n",
    "Submission ID: be449510-b190-4fae-9387-16f19a83f4f7\n",
    "\n",
    "4\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 18\n",
    "Mean advisor rating (all advisors, all grids): 0.9378541694451326\n",
    "Score: 0.33855510204081635\n",
    "Submission ID: 76ad3233-0c75-45db-abb0-a27624250e0c\n",
    "\n",
    "5\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 16\n",
    "Mean advisor rating (all advisors, all grids): 0.9419590764106018\n",
    "Score: 0.34891836734693876\n",
    "Submission ID: 5d532188-06a8-4755-a2f1-adfec25858e2\n",
    "\n",
    "after the selection of diverse grids\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 18\n",
    "Mean advisor rating (all advisors, all grids): 0.9290512422197501\n",
    "Score: 0.3576530612244898\n",
    "Submission ID: 7cd8bcb4-52ac-4e53-b9d6-4523c52e22ba\n",
    "\n",
    "out of top 1000\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 26\n",
    "Mean advisor rating (all advisors, all grids): 0.9074144134730059\n",
    "Score: 0.29511020408163263\n",
    "Submission ID: 715da021-fee3-479c-8d89-965bbf283da7\n",
    "\n",
    "out of 200\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 9\n",
    "Mean advisor rating (all advisors, all grids): 0.9516056723356537\n",
    "Score: 0.4150122448979592\n",
    "Submission ID: 979efc73-bc95-45ac-a7e6-8f88f74cbcda\n",
    "\n",
    "\n",
    "out of 200\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 6\n",
    "Mean advisor rating (all advisors, all grids): 0.9580031518265091\n",
    "Score: 0.4419265306122449\n",
    "Submission ID: 7dc28e59-0b49-46e7-a0e0-27fbea16fe53\n",
    "\n",
    "best 100 after generation 1 different\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 3\n",
    "Mean advisor rating (all advisors, all grids): 0.9661947331155596\n",
    "Score: 0.45669795918367345\n",
    "Submission ID: 07d7122d-c2f4-47f1-b9d8-23782773fd83\n",
    "\n",
    "second 100 after generation 1 different\n",
    "Submission Successful!\n",
    "Name: Patryk&Angela\n",
    "Nickname: Patryk&Angela\n",
    "# Invalid grids: 7\n",
    "Mean advisor rating (all advisors, all grids): 0.9571057667558083\n",
    "Score: 0.4366204081632653\n",
    "Submission ID: 278bcd2a-561b-499f-bccc-e0c1ca8a24a4\n",
    "\n",
    "Submission Successful!\n",
    "Name: P&A\n",
    "Nickname: P&A\n",
    "# Invalid grids: 8\n",
    "Mean advisor rating (all advisors, all grids): 0.9563033659106659\n",
    "Score: 0.44416326530612243\n",
    "Submission ID: 1efa721d-2ca2-4e05-b7cc-3d5b98162b2d\n",
    "\n",
    "\n",
    "Submission Successful!\n",
    "Name: P&A\n",
    "Nickname: P&A\n",
    "# Invalid grids: 1\n",
    "Mean advisor rating (all advisors, all grids): 0.9645268877404828\n",
    "Score: 0.49383673469387757\n",
    "Submission ID: 5689d589-d598-44ce-a1d4-adb0d9c0fd90\n",
    "\n",
    "with 2 different cells\n",
    "Submission Successful!\n",
    "Name: P&A\n",
    "Nickname: P&A\n",
    "# Invalid grids: 9\n",
    "Mean advisor rating (all advisors, all grids): 0.9459172273977517\n",
    "Score: 0.43793061224489793\n",
    "Submission ID: cad1525d-81c5-4deb-a5ed-a8bbe76008fd\n",
    "\n",
    "Submission Successful!\n",
    "Name: P&A\n",
    "Nickname: P&A\n",
    "# Invalid grids: 7\n",
    "Mean advisor rating (all advisors, all grids): 0.9532169353250773\n",
    "Score: 0.41968163265306124\n",
    "Submission ID: 37d0a701-a4d3-499f-bfd5-6414626507db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd07ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aaf210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from save_load_utils import save_prediction_data\n",
    "\n",
    "# Save the current data\n",
    "save_prediction_data(unique_grids, final_prediction_array)\n",
    "\n",
    "# Example of how to load it back (commented out as we already have the data in memory)\n",
    "# unique_grids_loaded, final_prediction_array_loaded = load_prediction_data()\n",
    "print(\"Data saved successfully to the 'saved_data' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3637e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from save_load_utils import load_prediction_data\n",
    "loaded_grids, loaded_predictions = load_prediction_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
